{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thadzy/Icanseeyourvoice/blob/main/New_Voice_Train_Thai_Test_Thai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load database\n",
        "\n"
      ],
      "metadata": {
        "id": "hOVdDl2LKU14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gA_rzyOKLqt"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "RNqjvQeRKd2Y",
        "outputId": "2bdc1ee6-ea48-48b5-b8e1-f4542e275e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b02345dd-670f-400d-8b79-dd437da2b1b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b02345dd-670f-400d-8b79-dd437da2b1b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"baslasiripatana\",\"key\":\"433bc7d2a1d608bf5097be88ff82aada\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "pRYLCZCDKf9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "uRFlQmlbKiP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "pTb3lN3SKk9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cK0hpD6KmwR",
        "outputId": "2f0015c6-3f96-4585-d97a-261a60d8e74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                 title                                        size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------------  ------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "thedrcat/daigt-v2-train-dataset                                     DAIGT V2 Train Dataset                       29MB  2023-11-16 01:38:36           1973        191  1.0              \n",
            "muhammadbinimran/housing-price-prediction-data                      Housing Price Prediction Data               763KB  2023-11-21 17:56:32           8855        153  1.0              \n",
            "everydaycodings/produce-prices-dataset                              Fruits and Vegetables Prices Dataset        232KB  2023-12-11 13:40:33           1457         30  1.0              \n",
            "thedevastator/books-sales-and-ratings                               Books Sales and Ratings                      53KB  2023-12-06 04:54:33           2112         30  1.0              \n",
            "spoorthiuk/us-top-10k-artists-and-their-popular-songs               US Top 10K Artists and Their Popular Songs    3MB  2023-12-13 17:49:48            641         21  1.0              \n",
            "thedevastator/netflix-imdb-scores                                   Netflix IMDB Scores                         699KB  2023-12-03 14:10:34           3467         55  1.0              \n",
            "jocelyndumlao/cardiovascular-disease-dataset                        Cardiovascular_Disease_Dataset              411KB  2023-12-09 06:51:28           1462         60  1.0              \n",
            "elvinrustam/imdb-movies-dataset                                     IMDb Movies                                   2MB  2023-12-07 20:59:09           1126         26  1.0              \n",
            "henryshan/starbucks                                                 Starbucks                                     5KB  2023-12-06 03:07:49           2324         53  1.0              \n",
            "tanshihjen/early-stage-diabetes-risk-prediction                     early_stage_diabetes_risk_prediction          3KB  2023-12-04 14:31:55            614         28  1.0              \n",
            "thedrcat/daigt-proper-train-dataset                                 DAIGT Proper Train Dataset                  119MB  2023-11-05 14:03:25           1824        150  1.0              \n",
            "jacksondivakarr/student-classification-dataset                      Student Classification Dataset               15KB  2023-12-02 16:23:43           2332         41  1.0              \n",
            "thedevastator/covid-19-global-case-and-death-data                   COVID-19 Global Case and Death Data          78MB  2023-12-04 16:16:58            627         22  0.9411765        \n",
            "carlmcbrideellis/llm-7-prompt-training-dataset                      LLM: 7 prompt training dataset               41MB  2023-11-15 07:32:56           1728        127  1.0              \n",
            "derrekdevon/real-estate-sales-2001-2020                             Real Estate Sales 2001-2020                  28MB  2023-12-07 15:36:26           1311         29  1.0              \n",
            "thedevastator/spotify-tracks-genre-dataset                          Spotify Tracks Genre                          8MB  2023-11-30 04:25:48           2532         65  1.0              \n",
            "sriharshaeedala/electricity-generated-in-us-by-sector               Electricity Generated in US by Sector        11KB  2023-11-29 17:14:36            639         22  1.0              \n",
            "ddosad/auto-sales-data                                              Automobile Sales data                        79KB  2023-11-18 12:36:41           5653         91  1.0              \n",
            "jeremylarcher/american-house-prices-and-demographics-of-top-cities  American House Prices                       666KB  2023-12-09 16:28:27            998         29  0.9411765        \n",
            "jacksondivakarr/online-shopping-dataset                             ðŸ›’ Online Shopping Dataset ðŸ“ŠðŸ“‰ðŸ“ˆ                 5MB  2023-11-12 12:35:58           5793         94  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d birdy654/deep-voice-deepfake-voice-recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKhoDygvKoxu",
        "outputId": "438c191a-7050-4da5-82a8-0bcdf392b779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deep-voice-deepfake-voice-recognition.zip to /content\n",
            "100% 3.68G/3.69G [01:58<00:00, 37.0MB/s]\n",
            "100% 3.69G/3.69G [01:58<00:00, 33.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip deep-voice-deepfake-voice-recognition.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nnDFtPCK1LI",
        "outputId": "7554df8f-8849-45c6-89ad-16929266fc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  deep-voice-deepfake-voice-recognition.zip\n",
            "  inflating: DEMONSTRATION/DEMONSTRATION/linus-original-DEMO.mp3  \n",
            "  inflating: DEMONSTRATION/DEMONSTRATION/linus-to-musk-DEMO.mp3  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/Obama-to-Biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/Obama-to-Trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-Obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-Trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/biden-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/linus-to-trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/margot-to-trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/musk-to-trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/obama-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/obama-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/obama-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/obama-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/obama-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/ryan-to-trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/taylor-to-trump.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-Biden.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-Obama.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-linus.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-margot.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-musk.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-ryan.wav  \n",
            "  inflating: KAGGLE/AUDIO/FAKE/trump-to-taylor.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/biden-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/linus-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/margot-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/musk-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/obama-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/ryan-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/taylor-original.wav  \n",
            "  inflating: KAGGLE/AUDIO/REAL/trump-original.wav  \n",
            "  inflating: KAGGLE/DATASET-balanced.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Test file"
      ],
      "metadata": {
        "id": "whSBJTb5LCM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z99HYJ6LLKBw",
        "outputId": "abaf4194-7b3d-43f3-81c4-28a03949c590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Replace 'YOUR_FOLDER_LINK' with the actual shareable link of the folder\n",
        "folder_link = 'https://drive.google.com/drive/folders/1hJWpn03uZCO_a462L9wE5P6JA-DznxgX'\n",
        "\n",
        "# Define a destination folder in Colab\n",
        "destination_folder = '/content/drive/MyDrive/Colab Notebooks/Downloaded_Folder'\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "os.makedirs(destination_folder, exist_ok=True)\n",
        "\n",
        "# Download the folder using gdown\n",
        "# gdown.download(folder_link, output=destination_folder, quiet=False)\n",
        "\n",
        "# Alternatively, if the above method does not work, you can try using gdown.download_folder\n",
        "gdown.download_folder(folder_link, output=destination_folder, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgfsL3hgLOWb",
        "outputId": "ff1774be-e93f-4f37-89f0-e44b82fdf2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder 1W557m4nPGYm1UHLeZZbi74OVejbVkyS8 REAL\n",
            "Processing file 1z73toVpT04oUY_sa7KZ689tu2OaKQaQW babyjingo.mp3\n",
            "Processing file 1SHOQiIg3C44sEyA5VKgwKsO5lN4lIEq4 BTSstation.mp3\n",
            "Processing file 1OsA9J0nF-6YDr_9yWaY7N6bRZR4fB5TB CEN.mp3\n",
            "Processing file 1eoccysrVhthzhicd-Ed8L5EEHlWefOCn CHEFPOM.mp3\n",
            "Processing file 1-57V9lKN0R9nSaydFkIR9YZfzeus5695 DADOFTHEGYPS.mp3\n",
            "Processing file 1u3CvRsRBZsKGGw2_1kO2vsas--xItKDF KAYKAI-WOODY.mp3\n",
            "Processing file 1SQiZb1a88S0UpY2UXjW73nMXv6oV7Su1 kyutae.mp3\n",
            "Processing file 19XNySQboRuctYV0S2vpOWlEQYvEXPgbu nutapiwich.mp3\n",
            "Processing file 1lGqQLKwi_jZHdQXbSOHGyc33JbHMB1YE Sample1_Cut.mp3\n",
            "Processing file 1vJX_E0YhyzjjKcMCqftkXp7uznFSYloK SampleThaiCut2.mp3\n",
            "Processing file 13ep-vrChnCxmJZeTKRsKLpMEV0m6YLMp SOUNDTISS.mp3\n",
            "Processing file 1m1skMqi9GaNvDD7ic3MjO-yinL0z1dUi TEDTALK-Pompam.mp3\n",
            "Processing file 1LawqCCiLt7gTyvRe81pUUIRZsv2DVY4Z THEGYPS.mp3\n",
            "Processing file 109hOvRhO188I8LYg1tZq1RkyOZ5a0H-n THIRD.mp3\n",
            "Processing file 1kuoMy5k5_64IH4J9Pn5-bVrPKFw70Fzl à¸ªà¸³à¹€à¸™à¸²à¸‚à¸­à¸‡ btsstation real.mp3\n",
            "Processing file 1_9OO68rrrRULlpT1Jl49psbLIR481c53 à¸ªà¸³à¹€à¸™à¸²à¸‚à¸­à¸‡ btsstation real.mp3\n",
            "Processing file 1STl76bKbrl7MNl_pA8JO_evYSFXizYUL à¸­à¸µà¸ªà¸¡à¸²à¸£à¸¹à¸­à¹‰à¸§à¸¢.mp3\n",
            "Building directory structure completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder list completed\n",
            "Building directory structure\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1z73toVpT04oUY_sa7KZ689tu2OaKQaQW \n",
            "\n",
            "Download ended unsuccessfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Test dataset.csv"
      ],
      "metadata": {
        "id": "80UwaEFOMqIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRYEXvbmNSc-",
        "outputId": "678a5bf6-12bb-421d-9d82-bcf6e9a0b005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def convert_mp3_to_wav(mp3_file_path, output_dir='converted_wav'):\n",
        "    \"\"\"\n",
        "    Converts an MP3 file to WAV format.\n",
        "\n",
        "    :param mp3_file_path: Path to the MP3 file.\n",
        "    :param output_dir: Directory where the converted WAV file will be saved.\n",
        "    :return: Path to the converted WAV file.\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Load MP3 file\n",
        "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
        "\n",
        "    # Construct WAV file path\n",
        "    wav_file_path = os.path.join(output_dir, os.path.basename(mp3_file_path).replace('.mp3', '.wav'))\n",
        "\n",
        "    # Export as WAV\n",
        "    audio.export(wav_file_path, format=\"wav\")\n",
        "    return wav_file_path\n",
        "\n",
        "def extract_features(wav_file_path):\n",
        "    \"\"\"\n",
        "    Extracts audio features from a WAV file similar to those in the dataset.\n",
        "\n",
        "    :param wav_file_path: Path to the WAV file.\n",
        "    :return: Dictionary of extracted features.\n",
        "    \"\"\"\n",
        "    # Load the audio file\n",
        "    y, sr = librosa.load(wav_file_path)\n",
        "\n",
        "    # Extract features\n",
        "    features = {\n",
        "        'chroma_stft': np.mean(librosa.feature.chroma_stft(y=y, sr=sr)),\n",
        "        'rms': np.mean(librosa.feature.rms(y=y)),\n",
        "        'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),\n",
        "        'spectral_bandwidth': np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),\n",
        "        'rolloff': np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),\n",
        "        'zero_crossing_rate': np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "    }\n",
        "\n",
        "    # Extract MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "    for i, mfcc in enumerate(mfccs):\n",
        "        features[f'mfcc{i+1}'] = np.mean(mfcc)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "i00BrSTTNKH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def process_and_save_to_csv(mp3_file_list, output_csv):\n",
        "    header = ['chroma_stft', 'rms', 'spectral_centroid', 'spectral_bandwidth',\n",
        "              'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4',\n",
        "              'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11',\n",
        "              'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18',\n",
        "              'mfcc19', 'mfcc20', 'LABEL']\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for mp3_file in mp3_file_list:\n",
        "        wav_file = convert_mp3_to_wav(mp3_file)\n",
        "        features = extract_features(wav_file)\n",
        "\n",
        "        if mp3_file.parent == Path(dataset_fake_path):\n",
        "            label = 'FAKE'\n",
        "        elif mp3_file.parent == Path(dataset_real_path):\n",
        "            label = 'REAL'\n",
        "        else:\n",
        "            label = 'UNKNOWN'  # Adjust as needed\n",
        "\n",
        "        # Concatenate the values of the dictionary and convert label to a list\n",
        "        row = np.concatenate([list(features.values()), [label]])\n",
        "        data.append(row)\n",
        "        # print(data)\n",
        "        # print(len(data))\n",
        "        # print(data[0].shape)\n",
        "        # print(data[1].shape)\n",
        "    df = pd.DataFrame(data, columns=header)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "\n",
        "# Create dataset.csv\n",
        "\n",
        "dataset_fake_path = '/content/Thai Dataset/FAKE'\n",
        "dataset_real_path = '/content/Thai Dataset/REAL'\n",
        "\n",
        "mp3_files_fake = Path(dataset_fake_path)\n",
        "mp3_files_real = Path(dataset_real_path)\n",
        "\n",
        "mp3_file_list_fake = list(mp3_files_fake.glob('*.mp3'))\n",
        "mp3_file_list_real = list(mp3_files_real.glob('*.mp3'))\n",
        "\n",
        "mp3_file_lists = mp3_file_list_fake + mp3_file_list_real\n",
        "\n",
        "output_csv_path = '/content/CSV/thai_test_dataset.csv'\n",
        "\n",
        "process_and_save_to_csv(mp3_file_lists, output_csv_path)\n"
      ],
      "metadata": {
        "id": "U4zKSiObNaWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "XtyGhEcaMDvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/CSV/thai_test_dataset.csv\")\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "print(X.head(10))\n",
        "print(y.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyfFBWfUMDN7",
        "outputId": "2a5ded4f-9048-4aec-be3e-eed01c0f7085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   chroma_stft       rms  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
            "0     0.251850  0.100741        1052.258507          956.591856  1832.247420   \n",
            "1     0.257549  0.116598        1274.622017         1167.473420  2318.720088   \n",
            "2     0.343675  0.046268        1331.280849         1253.597596  2373.983811   \n",
            "3     0.256747  0.082978        1279.501417         1034.379310  2282.448229   \n",
            "4     0.265698  0.058987        1441.025258         1124.350366  2491.383890   \n",
            "5     0.358537  0.032508        1442.027011         1228.037112  2649.614829   \n",
            "6     0.272934  0.090411        1515.576892         1409.558797  2786.011850   \n",
            "7     0.263140  0.098957        1145.445693         1019.444024  1996.137575   \n",
            "8     0.269326  0.082873        1436.774785         1364.820742  2850.937983   \n",
            "9     0.330473  0.069329        1510.763664         1504.920157  2948.557826   \n",
            "\n",
            "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
            "0            0.059156 -322.132996  101.814919 -16.587551  11.026052  ...   \n",
            "1            0.073549 -308.791077  107.481575 -14.388265  12.238509  ...   \n",
            "2            0.077375 -359.451691  139.131363 -33.182846  14.574292  ...   \n",
            "3            0.072271 -313.072357  106.864693 -48.186092  26.054010  ...   \n",
            "4            0.086365 -354.311188  100.587074 -48.147045  18.925644  ...   \n",
            "5            0.078489 -379.537079  113.517166 -39.881676  20.551210  ...   \n",
            "6            0.073608 -295.556091   85.315277 -27.147224  12.984956  ...   \n",
            "7            0.062978 -335.314331  115.034279 -11.948853  -3.643752  ...   \n",
            "8            0.060086 -321.585144  104.589554  -6.626234  47.277847  ...   \n",
            "9            0.069199 -311.720947  109.073799 -30.232798  33.000267  ...   \n",
            "\n",
            "      mfcc11     mfcc12     mfcc13    mfcc14     mfcc15     mfcc16     mfcc17  \\\n",
            "0 -14.716046 -13.296734  -8.289605 -1.430914 -11.023613 -13.254517  -6.280591   \n",
            "1 -24.773891  -9.157024 -11.218267 -0.237262 -16.428801 -14.137154  -5.831676   \n",
            "2  -5.981234 -11.137929 -10.626839  2.723548 -12.744275  -6.010058  -6.021200   \n",
            "3 -10.508437 -16.141336  -7.072448 -2.847350  -3.259974 -14.751692  -0.157817   \n",
            "4  -8.435124 -16.751707  -5.117518 -5.051587  -4.288020 -12.935152  -1.839343   \n",
            "5  -8.636992  -0.488815  -1.338882 -7.190503   0.409946  -3.842650 -10.960603   \n",
            "6 -18.478342  -8.521260 -14.497123  0.966572 -11.400728  -8.015926  -3.853328   \n",
            "7 -18.482557  -9.318172 -14.739877 -5.615003  -9.346701 -19.427189  -6.904489   \n",
            "8 -17.252699 -15.418329  -4.307316 -3.525014 -10.874050 -14.829860 -11.866947   \n",
            "9 -16.060274  -8.886692  -3.162179 -5.756738  -6.065518  -4.815185 -13.092113   \n",
            "\n",
            "      mfcc18     mfcc19     mfcc20  \n",
            "0  -8.267520  -9.024559  -7.048155  \n",
            "1 -14.355642  -5.403237 -15.166352  \n",
            "2  -9.767795  -6.253578  -1.667100  \n",
            "3  -7.885512 -11.935803  -1.661481  \n",
            "4  -8.859755  -9.715618  -1.628697  \n",
            "5  -5.544399  -4.117917  -2.718918  \n",
            "6  -5.759905  -5.793550   0.107929  \n",
            "7  -9.954145  -7.947601  -9.521993  \n",
            "8  -9.484370 -10.683495  -5.372654  \n",
            "9  -6.109950  -7.730844  -5.105124  \n",
            "\n",
            "[10 rows x 26 columns]\n",
            "0    FAKE\n",
            "1    FAKE\n",
            "2    FAKE\n",
            "3    FAKE\n",
            "4    FAKE\n",
            "5    FAKE\n",
            "6    FAKE\n",
            "7    FAKE\n",
            "8    FAKE\n",
            "9    FAKE\n",
            "Name: LABEL, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(y)\n",
        "y = lb.transform(y)\n",
        "y = y.ravel()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6mCbQ9MMX3U",
        "outputId": "a3f5ec49-1d10-42cb-8447-7c3477cb2b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5,  shuffle=True, random_state=1)\n",
        "\n",
        "print(model)\n",
        "print(\"KFold splits: \" + str(kf.get_n_splits(X)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mkrCnJ7P8dK",
        "outputId": "df69c948-be67-42e4-cbcf-d9b4149a5078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(n_estimators=50, random_state=1)\n",
            "KFold splits: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "\n",
        "acc_score = []\n",
        "prec_score = []\n",
        "rec_score = []\n",
        "f1s = []\n",
        "MCCs = []\n",
        "ROCareas = []\n",
        "\n",
        "start = time.time()\n",
        "for train_index , test_index in kf.split(X):\n",
        "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
        "    y_train , y_test = y[train_index] , y[test_index]\n",
        "\n",
        "    model.fit(X_train,y_train)\n",
        "    pred_values = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(pred_values , y_test)\n",
        "    acc_score.append(acc)\n",
        "\n",
        "    prec = precision_score(y_test , pred_values, average=\"binary\", pos_label=1)\n",
        "    prec_score.append(prec)\n",
        "\n",
        "    rec = recall_score(y_test , pred_values, average=\"binary\", pos_label=1)\n",
        "    rec_score.append(rec)\n",
        "\n",
        "    f1 = f1_score(y_test , pred_values, average=\"binary\", pos_label=1)\n",
        "    f1s.append(f1)\n",
        "\n",
        "    mcc = matthews_corrcoef(y_test , pred_values)\n",
        "    MCCs.append(mcc)\n",
        "\n",
        "    roc = roc_auc_score(y_test , pred_values)\n",
        "    ROCareas.append(roc)\n",
        "\n",
        "end = time.time()\n",
        "timeTaken = (end - start)\n",
        "print(\"Model trained in: \" + str( round(timeTaken, 2) ) + \" seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnA_4IeSMh9b",
        "outputId": "2d61232b-6f81-442e-9941-569824aa1d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in: 0.45 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean results and (std.):\\n\")\n",
        "print(\"Accuracy: \" + str( round(np.mean(acc_score)*100, 3) ) + \"% (\" + str( round(np.std(acc_score)*100, 3) ) + \")\\n\")\n",
        "print(\"Precision: \" + str( round(np.mean(prec_score), 3) ) + \" (\" + str( round(np.std(prec_score), 3) ) + \")\")\n",
        "print(\"Recall: \" + str( round(np.mean(rec_score), 3) ) + \" (\" + str( round(np.std(rec_score), 3) ) + \")\")\n",
        "print(\"F1-Score: \" + str( round(np.mean(f1s), 3) ) + \" (\" + str( round(np.std(f1s), 3) ) + \")\")\n",
        "print(\"MCC: \" + str( round(np.mean(MCCs), 3) ) + \" (\" + str( round(np.std(MCCs), 3) ) + \")\")\n",
        "print(\"ROC AUC: \" + str( round(np.mean(ROCareas), 3) ) + \" (\" + str( round(np.std(ROCareas), 3) ) + \")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puFTHDe5MnJJ",
        "outputId": "4beb01d7-7da6-4aa7-a825-232f9732c942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean results and (std.):\n",
            "\n",
            "Accuracy: 94.286% (11.429)\n",
            "\n",
            "Precision: 0.933 (0.133)\n",
            "Recall: 0.933 (0.133)\n",
            "F1-Score: 0.933 (0.133)\n",
            "MCC: 0.883 (0.233)\n",
            "ROC AUC: 0.942 (0.117)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Thai Dataset"
      ],
      "metadata": {
        "id": "nulrtlwkQJjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/CSV/thai_test_dataset.csv')\n",
        "\n",
        "X_thaitest = df.iloc[:,:-1]\n",
        "y_thaitest = df.iloc[:,-1]\n",
        "\n",
        "print(X_thaitest.head(10))\n",
        "print(y_thaitest.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BmVII1nQNAx",
        "outputId": "92dfe458-cede-4cb9-b577-6172215f16d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   chroma_stft       rms  spectral_centroid  spectral_bandwidth      rolloff  \\\n",
            "0     0.251850  0.100741        1052.258507          956.591856  1832.247420   \n",
            "1     0.257549  0.116598        1274.622017         1167.473420  2318.720088   \n",
            "2     0.343675  0.046268        1331.280849         1253.597596  2373.983811   \n",
            "3     0.256747  0.082978        1279.501417         1034.379310  2282.448229   \n",
            "4     0.265698  0.058987        1441.025258         1124.350366  2491.383890   \n",
            "5     0.358537  0.032508        1442.027011         1228.037112  2649.614829   \n",
            "6     0.272934  0.090411        1515.576892         1409.558797  2786.011850   \n",
            "7     0.263140  0.098957        1145.445693         1019.444024  1996.137575   \n",
            "8     0.269326  0.082873        1436.774785         1364.820742  2850.937983   \n",
            "9     0.330473  0.069329        1510.763664         1504.920157  2948.557826   \n",
            "\n",
            "   zero_crossing_rate       mfcc1       mfcc2      mfcc3      mfcc4  ...  \\\n",
            "0            0.059156 -322.132996  101.814919 -16.587551  11.026052  ...   \n",
            "1            0.073549 -308.791077  107.481575 -14.388265  12.238509  ...   \n",
            "2            0.077375 -359.451691  139.131363 -33.182846  14.574292  ...   \n",
            "3            0.072271 -313.072357  106.864693 -48.186092  26.054010  ...   \n",
            "4            0.086365 -354.311188  100.587074 -48.147045  18.925644  ...   \n",
            "5            0.078489 -379.537079  113.517166 -39.881676  20.551210  ...   \n",
            "6            0.073608 -295.556091   85.315277 -27.147224  12.984956  ...   \n",
            "7            0.062978 -335.314331  115.034279 -11.948853  -3.643752  ...   \n",
            "8            0.060086 -321.585144  104.589554  -6.626234  47.277847  ...   \n",
            "9            0.069199 -311.720947  109.073799 -30.232798  33.000267  ...   \n",
            "\n",
            "      mfcc11     mfcc12     mfcc13    mfcc14     mfcc15     mfcc16     mfcc17  \\\n",
            "0 -14.716046 -13.296734  -8.289605 -1.430914 -11.023613 -13.254517  -6.280591   \n",
            "1 -24.773891  -9.157024 -11.218267 -0.237262 -16.428801 -14.137154  -5.831676   \n",
            "2  -5.981234 -11.137929 -10.626839  2.723548 -12.744275  -6.010058  -6.021200   \n",
            "3 -10.508437 -16.141336  -7.072448 -2.847350  -3.259974 -14.751692  -0.157817   \n",
            "4  -8.435124 -16.751707  -5.117518 -5.051587  -4.288020 -12.935152  -1.839343   \n",
            "5  -8.636992  -0.488815  -1.338882 -7.190503   0.409946  -3.842650 -10.960603   \n",
            "6 -18.478342  -8.521260 -14.497123  0.966572 -11.400728  -8.015926  -3.853328   \n",
            "7 -18.482557  -9.318172 -14.739877 -5.615003  -9.346701 -19.427189  -6.904489   \n",
            "8 -17.252699 -15.418329  -4.307316 -3.525014 -10.874050 -14.829860 -11.866947   \n",
            "9 -16.060274  -8.886692  -3.162179 -5.756738  -6.065518  -4.815185 -13.092113   \n",
            "\n",
            "      mfcc18     mfcc19     mfcc20  \n",
            "0  -8.267520  -9.024559  -7.048155  \n",
            "1 -14.355642  -5.403237 -15.166352  \n",
            "2  -9.767795  -6.253578  -1.667100  \n",
            "3  -7.885512 -11.935803  -1.661481  \n",
            "4  -8.859755  -9.715618  -1.628697  \n",
            "5  -5.544399  -4.117917  -2.718918  \n",
            "6  -5.759905  -5.793550   0.107929  \n",
            "7  -9.954145  -7.947601  -9.521993  \n",
            "8  -9.484370 -10.683495  -5.372654  \n",
            "9  -6.109950  -7.730844  -5.105124  \n",
            "\n",
            "[10 rows x 26 columns]\n",
            "0    FAKE\n",
            "1    FAKE\n",
            "2    FAKE\n",
            "3    FAKE\n",
            "4    FAKE\n",
            "5    FAKE\n",
            "6    FAKE\n",
            "7    FAKE\n",
            "8    FAKE\n",
            "9    FAKE\n",
            "Name: LABEL, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(y_thaitest)\n",
        "y_thaitest = lb.transform(y_thaitest)\n",
        "y_thaitest = y_thaitest.ravel()\n",
        "print(y_thaitest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS6hrOeTQd7l",
        "outputId": "9a8cf77d-535a-42ee-d92b-52d5a302ac9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values = model.predict(X_thaitest)"
      ],
      "metadata": {
        "id": "nJwaKK14QveH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_values)"
      ],
      "metadata": {
        "id": "hN-M4bQIQ03s",
        "outputId": "17859d62-9db2-4e5a-92b4-741c0981055f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_score = []\n",
        "prec_score = []\n",
        "rec_score = []\n",
        "f1s = []\n",
        "MCCs = []\n",
        "ROCareas = []\n",
        "\n",
        "acc = accuracy_score(pred_values , y_thaitest)\n",
        "acc_score.append(acc)\n",
        "\n",
        "prec = precision_score(y_thaitest , pred_values, average=\"binary\", pos_label=1)\n",
        "prec_score.append(prec)\n",
        "\n",
        "rec = recall_score(y_thaitest , pred_values, average=\"binary\", pos_label=1)\n",
        "rec_score.append(rec)\n",
        "\n",
        "f1 = f1_score(y_thaitest , pred_values, average=\"binary\", pos_label=1)\n",
        "f1s.append(f1)\n",
        "\n",
        "mcc = matthews_corrcoef(y_thaitest , pred_values)\n",
        "MCCs.append(mcc)\n",
        "\n",
        "roc = roc_auc_score(y_thaitest, pred_values)\n",
        "ROCareas.append(roc)\n",
        "\n",
        "print(\"Mean results and (std.):\\n\")\n",
        "print(\"Accuracy: \" + str( round(np.mean(acc_score)*100, 3) ) + \"% (\" + str( round(np.std(acc_score)*100, 3) ) + \")\\n\")\n",
        "print(\"Precision: \" + str( round(np.mean(prec_score), 3) ) + \" (\" + str( round(np.std(prec_score), 3) ) + \")\")\n",
        "print(\"Recall: \" + str( round(np.mean(rec_score), 3) ) + \" (\" + str( round(np.std(rec_score), 3) ) + \")\")\n",
        "print(\"F1-Score: \" + str( round(np.mean(f1s), 3) ) + \" (\" + str( round(np.std(f1s), 3) ) + \")\")\n",
        "print(\"MCC: \" + str( round(np.mean(MCCs), 3) ) + \" (\" + str( round(np.std(MCCs), 3) ) + \")\")\n",
        "print(\"ROC AUC: \" + str( round(np.mean(ROCareas), 3) ) + \" (\" + str( round(np.std(ROCareas), 3) ) + \")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4yoQGULS_94",
        "outputId": "996683ec-f30f-4841-e1c9-7fb70eed2fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean results and (std.):\n",
            "\n",
            "Accuracy: 100.0% (0.0)\n",
            "\n",
            "Precision: 1.0 (0.0)\n",
            "Recall: 1.0 (0.0)\n",
            "F1-Score: 1.0 (0.0)\n",
            "MCC: 1.0 (0.0)\n",
            "ROC AUC: 1.0 (0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test English Voice"
      ],
      "metadata": {
        "id": "fzkuHGZqXm5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/CSV/eng_test_dataset.csv')\n",
        "\n",
        "X_thaitest = df.iloc[:,:-1]\n",
        "y_thaitest = df.iloc[:,-1]\n",
        "\n",
        "print(X_thaitest.head(10))\n",
        "print(y_thaitest.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "oxgS-PAyXv1R",
        "outputId": "0a21f03f-788a-46b0-84c4-a9e4e776b1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-9be2ac646726>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/CSV/eng_test_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_thaitest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/CSV/eng_test_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "lb.fit(y_thaitest)\n",
        "y_thaitest = lb.transform(y_thaitest)\n",
        "y_thaitest = y_thaitest.ravel()\n",
        "print(y_thaitest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeKdQAVwmnge",
        "outputId": "460087f5-f054-4c6c-c26d-eeb947b8f687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values = model.predict(X_thaitest)"
      ],
      "metadata": {
        "id": "Yst1-XH_muT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2d8NDAymvcP",
        "outputId": "fc53f187-2acf-41d0-c1e1-0ad732e4d7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "WUtV_ov032E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "1Svnv8Z-4GGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model, \"./random_forest_v2.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pGWeivy38ZT",
        "outputId": "437cb52c-76b6-47e4-c529-068a0ced9fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./random_forest_v2.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Siri voice"
      ],
      "metadata": {
        "id": "q26Zu-WXGKwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/Siri.mp3'\n",
        "wav_file = convert_mp3_to_wav(test_file)\n",
        "features = extract_features(wav_file)"
      ],
      "metadata": {
        "id": "rDOU5FoEGOhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnVLSBi8Kz0D",
        "outputId": "ef9c5178-975f-4460-a28b-e1bf0edbf91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chroma_stft': 0.28753564,\n",
              " 'rms': 0.057386935,\n",
              " 'spectral_centroid': 1686.270227818574,\n",
              " 'spectral_bandwidth': 1316.7305970380958,\n",
              " 'rolloff': 2943.050537109375,\n",
              " 'zero_crossing_rate': 0.11184488932291667,\n",
              " 'mfcc1': -370.54288,\n",
              " 'mfcc2': 107.30291,\n",
              " 'mfcc3': -9.483347,\n",
              " 'mfcc4': 17.231188,\n",
              " 'mfcc5': -5.7565355,\n",
              " 'mfcc6': -4.1298466,\n",
              " 'mfcc7': -12.382151,\n",
              " 'mfcc8': -7.7946477,\n",
              " 'mfcc9': -13.003581,\n",
              " 'mfcc10': -7.9390373,\n",
              " 'mfcc11': -11.80506,\n",
              " 'mfcc12': 0.13583872,\n",
              " 'mfcc13': -5.168755,\n",
              " 'mfcc14': 2.8077614,\n",
              " 'mfcc15': -2.0708346,\n",
              " 'mfcc16': -2.1977654,\n",
              " 'mfcc17': 3.4606993,\n",
              " 'mfcc18': -4.098655,\n",
              " 'mfcc19': 0.5016587,\n",
              " 'mfcc20': -6.298322}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = list(features.values())\n",
        "pred_values = model.predict([features_list])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35FlBvIBK5fY",
        "outputId": "09963f7e-f3b0-4d9b-d5e9-9230fff7a46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvf3YCkVNwqL",
        "outputId": "4eaae23d-3cf9-4e5a-e6c3-e458ac24623f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Thai Fake mp4\n"
      ],
      "metadata": {
        "id": "iMgRjwrdOHh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/Thai_Dataset/FAKE/à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡à¸„à¸·à¸­à¸«à¸±à¸§à¹ƒà¸ˆà¸‚à¸­à¸‡à¸à¸²à¸£à¹€à¸•....mp3'\n",
        "wav_file = convert_mp3_to_wav(test_file)\n",
        "features = extract_features(wav_file)"
      ],
      "metadata": {
        "id": "u3eAFcemN6Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = list(features.values())\n",
        "pred_values = model.predict([features_list])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e44928K6OB9S",
        "outputId": "8c2c7f80-82ed-4885-b8d7-1f5dd27d3a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYVcT_2IOEj7",
        "outputId": "d81388ce-5581-4d66-d786-a355a623979f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Thai Real mp4"
      ],
      "metadata": {
        "id": "Jmdr36_NOdD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/Thai_Dataset/REAL/CEN.mp3'\n",
        "wav_file = convert_mp3_to_wav(test_file)\n",
        "features = extract_features(wav_file)"
      ],
      "metadata": {
        "id": "wKv6QWILOQ6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = list(features.values())\n",
        "pred_values = model.predict([features_list])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmAoPyMCOZ5i",
        "outputId": "b74a8215-7b58-4e96-8b16-d5123aae3791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type([features_list])\n",
        "len([features_list][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYiVM8lHRH8b",
        "outputId": "0c5539e3-ab88-4533-d546-dca8ee201932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl48d7s_ObrF",
        "outputId": "9b91360d-ce28-4068-86d1-0145733d5eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test present fake"
      ],
      "metadata": {
        "id": "lu32rYuJcWtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/FAKE_TEST_CUT.mp3'\n",
        "wav_file = convert_mp3_to_wav(test_file)\n",
        "features = extract_features(wav_file)"
      ],
      "metadata": {
        "id": "zNbzvyqMccSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = list(features.values())\n",
        "pred_values = model.predict([features_list])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chGjrC5weYAy",
        "outputId": "90ed696a-068f-4a89-cc27-3da99b83df51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3ZS7mB0eba_",
        "outputId": "2cb6024b-7e7d-45f5-b229-589058850b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test present real"
      ],
      "metadata": {
        "id": "N5q8ITDSedJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_file = '/content/REAL_TEST_CUT.mp3'\n",
        "wav_file = convert_mp3_to_wav(test_file)\n",
        "features = extract_features(wav_file)"
      ],
      "metadata": {
        "id": "7WHNmrA2emvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_list = list(features.values())\n",
        "pred_values = model.predict([features_list])"
      ],
      "metadata": {
        "id": "rZV4YmkOerI_",
        "outputId": "0239747e-b2cc-4658-c0b4-b8cbc8161d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_values"
      ],
      "metadata": {
        "id": "rlQYKnVnesDD",
        "outputId": "f370853a-7b1c-4a84-e615-0aa199f601c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}